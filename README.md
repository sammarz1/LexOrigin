# ğŸŒ LexOrigin

> **Classify the country of origin of a text using NLP + Machine Learning.**

---

## ğŸ“ Project Structure

| File           | Description                                 |
|----------------|---------------------------------------------|
| `tokenizer.py` | ğŸ§¹ Functions to clean and tokenize text      |
| `model.py`     | ğŸ¤– Script to train and evaluate the model    |
| `scraper.ipynb`|    Script to scrape subreddits               |
| `complete_clean_data`|    Compressed file with sample data              |

---

## ğŸ“¥ What Data Do I Need?

Youâ€™ll need:

- ğŸ“ **Textual data** (e.g., articles, tweets, documents)
- ğŸ·ï¸ **Corresponding country labels**

**Example:**

| Text                             | Country     |
|----------------------------------|-------------|
| "Voy al parque a comer"          | Spain       |
| "Ayer me tomÃ© un mate"           | Argentina   |
| "me gustan los pinguinos weon"   | Chile       |

---

